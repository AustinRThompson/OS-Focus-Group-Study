---
title: "OS Focus Group: Data Preparation and Analysis"
author: "Austin Thompson, Ph.D., CCC-SLP"
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose

This is the data preparation and analysis script. Here, we combine and wrangle the raw transcription files, the coded phrases, and the codebook data. In this document, we create combined frequency count CSV files to show the codes and the comments they describe. We also create some vizualizations for some of the findings.

Link to OSF Project Page: https://osf.io/tprzu/

# Packages
Loading in the required packages.
```{r}
library(tidyverse) # install.packages('tidyverse')
library(viridis)  # install.packages('viridis')
library(tm) # install.packages('tm')
library(extrafont) # install.packages('extrafont')
```

# Loading the Data
## Function to Load the Transcripts
Function for loading and cleaning the transcripts.
```{r}
readTranscript <- function(file, transcriptName, commentRows) {
  transcript <- utils::read.delim(file,
                                   fileEncoding="UTF-8") %>%
  as.data.frame() %>%
  
  # Renaming the data to be Comments, and removing the empty lines
  dplyr::rename(Comment = 1) %>%
  dplyr::filter(Comment != "") %>%
  
  # Filtering just the comments, excluding the comments
  dplyr::filter(between(row_number(),commentRows[1],commentRows[2])) %>%
  
  # Creating a transcript column, generating the participant ID's from the columns, and prepping for when a comment was separated into two paragraphs
  dplyr::mutate(Transcript = transcriptName,
                Participant = gsub("\\:.*", "", Comment),
                altParticipant = lag(Participant,1),
                commentNumber = row_number(),
                altCommentNumber = lag(commentNumber,1)) %>%
  dplyr::relocate(Comment, .after = Participant) %>%
  
  # Merging when the comment went to a second line
  dplyr::mutate(Participant = ifelse(Participant == Comment,
                                     altParticipant,
                                     Participant),
                newLine = case_when(
                  .$Participant %in% .$Comment ~ "TRUE",
                  TRUE ~ "FALSE"
                ),
                commentNumber = ifelse(newLine == TRUE,
                                     altCommentNumber,
                                     commentNumber),
                commentNumber = case_when(
                  Transcript == "nonR1_2" & commentNumber == 58 ~ 59,
                  TRUE ~ commentNumber
                ),
                Participant = case_when(
                  # Here, we are fixing an issue with participant 11, whose comment went to a second line
                  Participant == "So yeah, I I did make myself a personal website, and it does take a lot of time and work, and" ~ "11",
                  TRUE ~ Participant
                )) %>%
  
  # Finding the comments that went onto new lines and merging them with the previous comment
    dplyr::group_by(Transcript, Participant, commentNumber) %>% 
    dplyr::mutate(Comment = paste0(Comment, collapse = " ")) %>%
    dplyr::ungroup() %>%
    dplyr::select(!c(altParticipant,altCommentNumber, newLine)) %>%
    dplyr::distinct(.keep_all = T) %>%
    
  # Remaking the comment numbers with the new distinct data
    dplyr::mutate(commentNumber = row_number()) %>%
    
    # Changing instances of [University] to (University) so they arent removed in the next step
    dplyr::mutate(Comment = gsub(
      pattern = "[university]",
      replacement = "(university)",
      x = Comment,
      fixed = TRUE)) %>%
  
  # Remove the square brackets that were inserted due to coding/comments
  dplyr::mutate(Comment = gsub("\\[[^][]*]", "", Comment), # here i need to make sure it doesnt remove [university]
                Participant = gsub("\\[[^][]*]", "", Participant))
  
  return(transcript)
}
```

## Loading the Transcripts
Loading the transcripts that were exported from Microsoft Word as .txt files.
```{r}
# R1 1
transcript_R1_1 <- readTranscript(
  file = "Data/Raw Data/Transcripts/MASTER_R1_Transcript_2023_05_15.txt",
  transcriptName = "R1_1",
  commentRows = c(2,127)
)

# R1 2
transcript_R1_2 <- readTranscript(
  file = "Data/Raw Data/Transcripts/MASTER_R1_transcript_2023_05_22.txt",
  transcriptName = "R1_2",
  commentRows = c(2,134)
)

# nonR1 1
transcript_nonR1_1 <- readTranscript(
  file = "Data/Raw Data/Transcripts/MASTER CONSENSUS_NonR1_Transcript_2023_07_20.txt",
  transcriptName = "nonR1_1",
  commentRows = c(2,170)
)

# nonR1 2
transcript_nonR1_2 <- readTranscript(
  file = "Data/Raw Data/Transcripts/MASTER CONSENSUS_NonR1_Transcript_2023_05_15.txt",
  transcriptName = "nonR1_2",
  commentRows = c(2,112)
)

# Combining the four transcripts into a single master transcropt
masterTranscript <- rbind(
  transcript_R1_1,
  transcript_R1_2,
  transcript_nonR1_1,
  transcript_nonR1_2) %>%
  dplyr::mutate(
    Participant = case_when(
      
      # When the participant was the facilitator, leave their ID as F
      Participant == "F" ~ "F",
      
      # For all other participants, format them as 01, 02, etc
      Participant != "F" ~ sprintf("%02d", as.numeric(Participant)),
    ),
    Participant = case_when(
     
      # When the participant was the facilitator, leave their ID as F
      Participant == "F" ~ "F",
      
      # When the participant was from the nonR1 transcript, add "nR1-" to their ID.
      grepl(pattern = "nonR1", Transcript) == TRUE ~ paste0("nR1-", Participant),
      
      # When the participant was from the R1 transcript, add "R1-" to their ID.
      grepl(pattern = "R1", Transcript) == TRUE ~ paste0("R1-", Participant)
  ))

# Removing the four individual transcripts
rm(transcript_R1_1,
  transcript_R1_2,
  transcript_nonR1_1,
  transcript_nonR1_2)

# Exporting the master transcript to the prepped data folder.
utils::write.csv(
  x = masterTranscript,
  file = "Data/Prepped Data/masterTranscript.csv",
  fileEncoding = "UTF-8")
```

## Load the Codes & References
In the previous block, we loaded in the transcripts and created a Master Transcript. 

Now we need to load in the coded phrases, which we will then align with the Master Transcript comments. These codes & phrases were extracted from the Microsoft Word documents using a custom Macro (in the github, labeled `macro_ExportComments`) and were exported to the `Raw Data/Codes & References` folder as CSV files.
```{r}
codeReferences_nonR1_1 <- read.csv(
  file = "Data/Raw Data/Codes & References/CodeReferences_nonR1_1.csv",
  encoding="UTF-8") %>%
  dplyr::mutate(Transcript = "nonR1_1")

codeReferences_nonR1_2 <- read.csv(
  file = "Data/Raw Data/Codes & References/CodeReferences_nonR1_2.csv",
  encoding="UTF-8") %>%
  dplyr::mutate(Transcript = "nonR1_2")

codeReferences_R1_1 <- read.csv(
  file = "Data/Raw Data/Codes & References/CodeReferences_R1_1.csv",
  encoding="UTF-8") %>%
  dplyr::mutate(Transcript = "R1_1")

codeReferences_R1_2 <- read.csv(
  file = "Data/Raw Data/Codes & References/CodeReferences_R1_2.csv",
  encoding="UTF-8") %>%
  dplyr::mutate(Transcript = "R1_2")

# Combining the four codeReferences into one
codeReferences <- rbind(
  codeReferences_nonR1_1,
  codeReferences_nonR1_2,
  codeReferences_R1_1,
  codeReferences_R1_2
) %>%
  dplyr::relocate(Transcript, .before = Page) %>%
  dplyr::rename(Code = Comment,
                Comment = `Reference.Text`,
                Date = `Date...Time`) %>%
  
  # Filtering out non-code comments. These are comments that were not codes, but notes to the coding team.
  dplyr::filter(!grepl(pattern = "_Re-opened_", x = Code)) %>%
  dplyr::filter(!grepl(pattern = "_Marked as resolved_", x = Code)) %>%
  dplyr::filter(!grepl(pattern = "started coding first 3 responses for", x = Code)) %>%
  dplyr::filter(!grepl(pattern = "Note:", x = Code))

# Export the codeReferences to the Prepped Data folder.
utils::write.csv(
  x = codeReferences,
  file = "Data/Prepped Data/codeReferences.csv",
  fileEncoding = "UTF-8")

rm(codeReferences_nonR1_1,
  codeReferences_nonR1_2,
  codeReferences_R1_1,
  codeReferences_R1_2
)
```

## Codebook Data
So, now we have the (1) Master Transcripts (i.e., the combination of all of the transcripts), (2) Coded References (i.e., the phrases within the transcripts and their corresponding codes).

Now, we will load in the codebooks, which describe what the codes mean. We have several codebooks: (1) Initial (cb_Initial), (2) Axial (cb_Axial), and (3) Subcategory (cb_Subcat), and (4) Categories (cb_Cat). We are loading all of these in, so that we can calculate the frequency counts for codes as each level of this coding scheme. Importantly, initial codes were merged together to make the axial codes. Axial codes were merged together to create the subcategory codes. Finally, subcategory codes were merged together to make the category codes. So, the codebook data are nested.
```{r}
cb_Initial <- read.csv(
  file = "Data/Raw Data/Codebook Data/Initial Codebook.csv",
  fileEncoding = "UTF-8"
) %>%
  dplyr::rename(initialCode = 2,
                codeName = 3,
                definition = 4) %>%
  dplyr::select(initialCode:definition) %>%
  dplyr::filter(initialCode != "")

cb_Axial <- read.csv(
  file = "Data/Raw Data/Codebook Data/Axial Codebook.csv",
  fileEncoding = "UTF-8"
) %>%
  dplyr::rename(axialCode = 2,
                initialCode = 3,
                codeName = 4,
                definition = 5) %>%
  dplyr::select(axialCode:definition) %>%
  dplyr::filter(initialCode != "")

cb_Subcat <- read.csv(
  file = "Data/Raw Data/Codebook Data/Subcategory Codebook.csv",
  fileEncoding = "UTF-8"
) %>%
  dplyr::rename(axialCode = 3,
                codeName = 4,
                keywords = 5,
                definition = 6) %>%
  dplyr::select(c(Subcategory,axialCode)) %>%
  dplyr::filter(axialCode != "")

cb_Cat <- read.csv(
  file = "Data/Raw Data/Codebook Data/Category Codebook.csv",
  fileEncoding = "UTF-8"
) %>%
  dplyr::filter(Category != "") %>%
  unique()

# Creating the Master Codebook
cb_master <- base::merge(cb_Axial,cb_Subcat, all = TRUE, no.dups = F) %>%
  base::merge(.,cb_Cat, all = TRUE, no.dups = F) %>%
  dplyr::select(Category, Subcategory, axialCode, initialCode, codeName, definition)
  
# Export the Master Codebook
utils::write.csv(
  x = cb_master,
  file = "Data/Prepped Data/Master Codebook.csv",
  fileEncoding = "UTF-8")

# Removong the four individual codebooks.
rm(cb_Axial,
   cb_Initial,
   cb_Subcat,
   cb_Cat)
```

## Merging codeReferences and masterTrasncript
Now we want to merge the Master Transcript with the Code References to make the `CodedMasterTranscripts`. This will allow us to determine which full comment the coded phrase was obtained from.
```{r}
# Load in the codeReferences
codeReferences <- utils::read.csv(
  file = "Data/Prepped Data/codeReferences.csv",
  fileEncoding = "UTF-8") %>%
  dplyr::mutate(fullCode = Code) %>%
  tidyr::separate(Code, c("1", "2", "3", "4", "5", "6", "7"), ",") %>%
  tidyr::pivot_longer(cols = `1`:`7`,
                      values_to = "code") %>%
  dplyr::select(!name) %>%
  dplyr::filter(!is.na(code)) %>%
  
  # Remove and spaces in the code (example "B - T" would turn into "B-T")
  dplyr::mutate(code = gsub(pattern = " ",
                            replacement = "",
                            code)) %>%
  dplyr::select(!X) %>%
  dplyr::mutate(fullComment = NA,
                Participant = NA,
                Comment = gsub(pattern = "<P>",
                               replacement = " ",
                               x = Comment)) %>%
  # Changing instances of [University] to (University) so they aren't removed in the next step
    dplyr::mutate(Comment = gsub(
      pattern = "[university]",
      replacement = "(university)",
      x = Comment,
      fixed = TRUE))

# This is a loop that goes
NC <- 1
while(NC <= NROW(codeReferences)) {
  
  # In the master transcript, let's find which comment the coded phrase comes from.
  comment <- masterTranscript %>%
    dplyr::filter(stringr::str_detect(string = masterTranscript$Comment,
                    pattern = fixed(codeReferences$Comment[NC]))) %>%
    dplyr::filter(Transcript == codeReferences$Transcript[NC])
  
  if (NROW(comment) == 0) {
    commentReference <- codeReferences %>%
    slice(NC)
  } else {
    #
    commentReference <- codeReferences %>%
    slice(NC) %>%
    dplyr::mutate(fullComment = comment$Comment,
                  Participant = comment$Participant)
  }
  
  # Creating the codedMasterTranscript, which is the combination of codeReferences and the masterTranscript
  if(NC == 1) {
    codedMasterTranscript <- commentReference
  } else {
    codedMasterTranscript <- codedMasterTranscript %>%
      rbind(.,commentReference)
  }
  
  NC <- NC + 1
  
  rm(commentReference)
}

rm(comment)

# Export the Master Codebook
utils::write.csv(
  x = codedMasterTranscript,
  file = "Data/Prepped Data/Master Codebook_coded.csv",
  fileEncoding = "UTF-8")

```

# Obtaining Frequency Counts
```{r}
# Getting rid of redundancy - If a person brought up a code several times (e.g., PE-SA [previous experience - self-archiving], we only want to count that once)
uniqueCodes <- rio::import(
  file = "Data/Prepped Data/Master Codebook_coded.csv",
  fileEncoding = "UTF-8") %>%
  dplyr::mutate(Comment = paste0(Participant,": ",Comment)) %>%
  
  # Collapse all of the comments across transcripts, participants, and codes into the Comment variable
  dplyr::group_by(Transcript, Participant, code) %>%
  dplyr::summarize(Comment = paste0(Comment, collapse = " // ")) %>%
  dplyr::ungroup()

# Merging the unique codes with the Master Codebook
allUniqueCodes <- cb_master %>%
  dplyr::select(Category:codeName) %>%
  dplyr::rename(code = initialCode) %>%
  base::merge(uniqueCodes, .) %>%
  dplyr::relocate(Category:codeName, .before = code) %>%
  dplyr::rename(AxialCode = axialCode,
                InitialCode = code,
                InitialCodeName = codeName) %>%
  arrange(Category)

rm(uniqueCodes)
```

## Initial Code Frequency Count
```{r}
## By Group
freq_initial <- allUniqueCodes %>%
  dplyr::mutate(Group = case_when(
    Transcript == "R1_1" ~ "R1",
    Transcript == "R1_2" ~ "R1",
    Transcript == "nonR1_1" ~ "non-R1",
    Transcript == "nonR1_2" ~ "non-R1",
  )) %>%
  dplyr::group_by(Group, Category, Subcategory, AxialCode, InitialCode, InitialCodeName) %>% 
  dplyr::summarize(Comment = paste0(Comment, collapse = " // "),
                   N = sum(NROW(InitialCode))) %>%
  dplyr::ungroup() %>%
  dplyr::relocate(N, .before = Comment)

utils::write.csv(
  x = freq_initial,
  file = "Data/Prepped Data/Frequency Counts_by Group/Freq_Initial Codes.csv",
  fileEncoding = "UTF-8")

## All Participants
freq_initial <- allUniqueCodes %>%
  dplyr::group_by(Category, Subcategory, AxialCode, InitialCode, InitialCodeName) %>% 
  dplyr::summarize(Comment = paste0(Comment, collapse = " // "),
                   N = sum(NROW(InitialCode))) %>%
  dplyr::ungroup() %>%
  dplyr::relocate(N, .before = Comment)

utils::write.csv(
  x = freq_initial,
  file = "Data/Prepped Data/Frequency Counts/Freq_Initial Codes.csv",
  fileEncoding = "UTF-8")
```

## Axial Code Frequency Count
```{r}
## By Group
freq_axial <- allUniqueCodes %>%
  dplyr::mutate(Group = case_when(
    Transcript == "R1_1" ~ "R1",
    Transcript == "R1_2" ~ "R1",
    Transcript == "nonR1_1" ~ "non-R1",
    Transcript == "nonR1_2" ~ "non-R1",
  )) %>%
  dplyr::group_by(Group, Category, Subcategory, AxialCode) %>% 
  dplyr::summarize(Comment = paste0(Comment, collapse = " // "),
                   N = sum(NROW(AxialCode))) %>%
  dplyr::ungroup() %>%
  dplyr::relocate(N, .before = Comment) %>%
  as.tibble() %>%
  base::merge(., read.csv(file = "Data/Raw Data/Codebook Data/Axial Codenames.csv") %>%
                dplyr::select(`Code.abbreviation`,`Full.code.name`) %>%
                dplyr::rename(AxialCode = 1,
                              AxialCodeName = 2),
              all.x = TRUE) %>%
  dplyr::relocate(c(AxialCode, AxialCodeName), .before = N) %>%
  arrange(Group, Category)

utils::write.csv(
  x = freq_axial,
  file = "Data/Prepped Data/Frequency Counts_by Group/Freq_Axial Codes.csv",
  fileEncoding = "UTF-8")

## All Participants
freq_axial <- allUniqueCodes %>%
  dplyr::group_by(Category, Subcategory, AxialCode) %>% 
  dplyr::summarize(Comment = paste0(Comment, collapse = " // "),
                   N = sum(NROW(AxialCode))) %>%
  dplyr::ungroup() %>%
  dplyr::relocate(N, .before = Comment) %>%
  as.tibble() %>%
  base::merge(., read.csv(file = "Data/Raw Data/Codebook Data/Axial Codenames.csv") %>%
                dplyr::select(`Code.abbreviation`,`Full.code.name`) %>%
                dplyr::rename(AxialCode = 1,
                              AxialCodeName = 2),
              all.x = TRUE) %>%
  dplyr::relocate(c(AxialCode, AxialCodeName), .before = N) %>%
  arrange(Category)

utils::write.csv(
  x = freq_axial,
  file = "Data/Prepped Data/Frequency Counts/Freq_Axial Codes.csv",
  fileEncoding = "UTF-8")
```

## Subcategory Code Frequency Count
```{r}
## By Group
freq_Subcategory <- allUniqueCodes %>%
  dplyr::mutate(Group = case_when(
    Transcript == "R1_1" ~ "R1",
    Transcript == "R1_2" ~ "R1",
    Transcript == "nonR1_1" ~ "non-R1",
    Transcript == "nonR1_2" ~ "non-R1",
  )) %>%
  dplyr::group_by(Group, Category, Subcategory) %>% 
  dplyr::summarize(Comment = paste0(Comment, collapse = " // "),
                   N = sum(NROW(InitialCode))) %>%
  dplyr::ungroup() %>%
  dplyr::relocate(N, .before = Comment)

utils::write.csv(
  x = freq_Subcategory,
  file = "Data/Prepped Data/Frequency Counts_by Group/Freq_Subcategory Codes.csv",
  fileEncoding = "UTF-8")

## All Participants
freq_Subcategory <- allUniqueCodes %>%
  dplyr::group_by(Category, Subcategory) %>% 
  dplyr::summarize(Comment = paste0(Comment, collapse = " // "),
                   N = sum(NROW(InitialCode))) %>%
  dplyr::ungroup() %>%
  dplyr::relocate(N, .before = Comment)

utils::write.csv(
  x = freq_Subcategory,
  file = "Data/Prepped Data/Frequency Counts/Freq_Subcategory Codes.csv",
  fileEncoding = "UTF-8")
```

## Category Code Frequency Count
```{r}
## By Group
freq_Category <- allUniqueCodes %>%
  dplyr::mutate(Group = case_when(
    Transcript == "R1_1" ~ "R1",
    Transcript == "R1_2" ~ "R1",
    Transcript == "nonR1_1" ~ "non-R1",
    Transcript == "nonR1_2" ~ "non-R1",
  )) %>%
  dplyr::group_by(Group, Category) %>% 
  dplyr::summarize(Comment = paste0(Comment, collapse = " // "),
                   N = sum(NROW(InitialCode))) %>%
  dplyr::ungroup() %>%
  dplyr::relocate(N, .before = Comment)

utils::write.csv(
  x = freq_Category,
  file = "Data/Prepped Data/Frequency Counts_by Group/Freq_Category Codes.csv",
  fileEncoding = "UTF-8")

## All Participants
freq_Category <- allUniqueCodes %>%
  dplyr::group_by(Category) %>% 
  dplyr::summarize(Comment = paste0(Comment, collapse = " // "),
                   N = sum(NROW(InitialCode))) %>%
  dplyr::ungroup() %>%
  dplyr::relocate(N, .before = Comment)

utils::write.csv(
  x = freq_Category,
  file = "Data/Prepped Data/Frequency Counts/Freq_Category Codes.csv",
  fileEncoding = "UTF-8")

```

# Plots
## Figure 3 - What they want to learn
```{r}
Pal <- c("#4F6980",
         "#849DB1",
         "#A2CEAA",
         "#638B66",
         "#F47942",
         "#FBB04E",
         "#B66353",
         "#D7CE9F")

WTL <- read.csv(
  file = "Data/Prepped Data/Frequency Counts_by Group/Freq_Initial Codes.csv"
) %>%
  dplyr::filter(Subcategory == "3.1 - Information") %>%
  dplyr::group_by(Group,Subcategory,InitialCode) %>%
  dplyr::summarise(N = sum(N)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(proportion = (N / sum(N))*100) %>%
  dplyr::group_by(Subcategory,InitialCode) %>%
  dplyr::mutate(allN = sum(N)) %>%
  dplyr::ungroup() %>%
  #arrange(allN) %>%
  dplyr::filter(InitialCode != "LP-P") %>%
  dplyr::filter(InitialCode != "LP-C") %>%
  dplyr::filter(InitialCode != "LP-PPOV") %>%
  dplyr::mutate(
    Group = factor(Group, levels = c("R1", "non-R1")),
    Topic = case_when(
      grepl(pattern = "SA",InitialCode) ~ "Self-Archiving",
      grepl(pattern = "OA",InitialCode) ~ "Open Access",
      grepl(pattern = "OM",InitialCode) ~ "Open Materials",
      grepl(pattern = "OD",InitialCode) ~ "Open Data",
      grepl(pattern = "OER",InitialCode) ~ "Open Education Resources",
      grepl(pattern = "OSW", InitialCode) ~ "Open Science Workflow",
      grepl(pattern = "OS", InitialCode) ~ "All OS Practices",
      grepl(pattern = "OPR", InitialCode) ~ "Open Peer Review",
      grepl(pattern = "PR", InitialCode) ~ "Preregistration",
      grepl(pattern = "NIH", InitialCode) ~ "NIH Procedures",
      grepl(pattern = "IRB", InitialCode) ~ "IRB Policies",
      grepl(pattern = "IP", InitialCode) ~ "Institutional Policies",
    ),
    Type = case_when(
      Topic == "All OS Practices" ~ "Practices",
      Topic == "Preregistration" ~ "Practices",
      Topic == "Self-Archiving" ~ "Practices",
      Topic == "Open Access" ~ "Practices",
      Topic == "Open Data" ~ "Practices",
      Topic == "Open Peer Review" ~ "Practices",
      Topic == "Open Materials" ~ "Practices",
      Topic == "Open Education Resources" ~ "Practices",
      TRUE ~ "Procedures"
    )) %>%
  dplyr::group_by(Type) %>%
  dplyr::arrange(Topic)

WTL %>%
  dplyr::mutate(label = paste0("  ", Group," (",round(proportion,digits = 2),"%)")) %>%
  ggplot() +
  aes(y = N,
      x = Topic,
      alpha = Group) +
  
  geom_bar(stat = "identity",
           fill = Pal[1]) +
  
  # Labels - Currently suppressed
  #geom_text(aes(y = allN),
  #          position = position_dodge2(width = 0.9, preserve = "single"),
  #          alpha = .4,
  #          vjust=0.25,
  #          hjust=0) +
  
  # Changing the alpha values
  scale_alpha_manual(values = c(.6,1)) +

  # Modifying the theme
  theme_minimal() +
  theme(
    # remove the vertical grid lines
    panel.grid.major.y = element_blank(),

    legend.position = "right",
    axis.text.y = element_text(hjust = 1),
    text = element_text(family="Arial")) +
  
  # Modifying the axis labels
  labs(y = NULL,
       x = NULL) +
  
  # Flipping the axes
  scale_x_discrete(limits=rev) +
  coord_flip() +
  
  # Facet
  facet_wrap(~Type,
             ncol = 1,
             scales = "free_y")

ggsave(
  plot = last_plot(),
  filename = "Figures/Figure 3_WTL Topics.png",
  height = 6,
  width = 8,
  units = "in",
  scale = .8,
  bg = "white"
)

rio::export(
WTL %>%
  dplyr::select(Group, Type, Topic, N, TopicN = allN) %>%
  arrange(Type, Topic, Group),
file = "Figures/Figure 3_Alt text counts.csv")

```

## Figure 4 - Knowledge & Experience
```{r}
Pal <- c("#4F6980",
         "#849DB1",
         "#A2CEAA",
         "#638B66",
         "#F47942",
         "#FBB04E",
         "#B66353",
         "#D7CE9F")


knowledgeExperience <- read.csv(
  file = "Data/Prepped Data/Frequency Counts_by Group/Freq_Initial Codes.csv"
) %>%
  dplyr::filter(grepl(pattern = "KOP-|U-|PE-|LPE-",
                      x = InitialCode)) %>%
  dplyr::mutate(
    Domain = case_when(
      grepl(pattern = "U-",InitialCode) ~ "Uncertain About...",
      grepl(pattern = "KOP-",InitialCode) ~ "Knowledgeable About...",
      grepl(pattern = "LPE-",InitialCode) ~ "No Prior Experience With...",
      grepl(pattern = "PE-",InitialCode) ~ "Prior Experience With..."),
    Domain = factor(Domain, levels = c("Knowledgeable About...",
                                       "Uncertain About...",
                                       "Prior Experience With...",
                                       "No Prior Experience With...")),
    FacetTopic = case_when(
      Domain == "Uncertain About..." ~ "Knowledge",
      Domain == "Knowledgeable About..." ~ "Knowledge",
      Domain == "No Prior Experience With..." ~ "Experience",
      Domain == "Prior Experience With..." ~ "Experience"
    ),
    Topic = case_when(
      grepl(pattern = "SA",InitialCode) ~ "Self-Archiving",
      grepl(pattern = "OA",InitialCode) ~ "Open Access",
      grepl(pattern = "OM",InitialCode) ~ "Open Materials",
      grepl(pattern = "OD",InitialCode) ~ "Open Data",
      grepl(pattern = "OER",InitialCode) ~ "Open Education Resources",
      grepl(pattern = "OS", InitialCode) ~ "Open Science (General)",
      grepl(pattern = "PR", InitialCode) ~ "Preregistration",
      grepl(pattern = "NIH", InitialCode) ~ "NIH Procedures",
    ),
    Group = factor(Group, levels = c("R1", "non-R1")),
    Topic = factor(Topic, levels = c("Open Science (General)",
                                     "Open Access",
                                     "Self-Archiving",
                                     "Preregistration",
                                     "Open Data",
                                     "Open Materials",
                                     "NIH Procedures",
                                     "Open Education Resources"
                                     ))) %>%
  arrange(desc(N))

knowledgePlot <- knowledgeExperience %>%
  dplyr::filter(FacetTopic == "Knowledge") %>%
  dplyr::group_by(Group, Domain, Topic) %>%
  dplyr::summarise(N = sum(N)) %>%
  ggplot() +
  aes(
    y = N,
    x = Group,
    fill = Topic,
  ) +
  
  
  geom_bar(position="stack", stat="identity") +
  facet_grid(~Domain,
             scales = "free_x") +
  
  # Colors
  scale_fill_manual(values = Pal) +
  
  # Modifying the theme
  theme_minimal() +
  theme(
    # remove the vertical grid lines
    panel.grid.major.x = element_blank(),

    legend.position = "right",
    #axis.text.x = element_text(hjust = 1),
    text = element_text(family="Arial")) +
  
  
  # Modifying the axis labels
  labs(y = NULL,
       x = NULL,
       title = "Knowledge") +
  
  # Flipping the axes
  coord_cartesian(clip = "off")

experiencePlot <- knowledgeExperience %>%
  dplyr::filter(FacetTopic == "Experience") %>%
  dplyr::group_by(Group, Domain, Topic) %>%
  dplyr::summarise(N = sum(N)) %>%
  ggplot() +
  aes(
    y = N,
    x = Group,
    fill = Topic,
  ) +
  
  
  geom_bar(position="stack", stat="identity") +
  facet_grid(~Domain,
             scales = "free_x") +
  
  # Colors
  scale_fill_manual(values = Pal) +
  
  # Modifying the theme
  theme_minimal() +
  theme(
    # remove the vertical grid lines
    panel.grid.major.x = element_blank(),

    legend.position = "right",
    #axis.text.x = element_text(hjust = 1),
    text = element_text(family="Arial")) +
  
  
  # Modifying the axis labels
  labs(y = NULL,
       x = NULL,
       title = "Experience") +
  
  # Flipping the axes
  coord_cartesian(clip = "off")

F2 <- knowledgePlot + experiencePlot +
  #patchwork::guide_area() +
  theme(legend.position = "right")+
  patchwork::plot_layout(ncol = 1, guides = "collect")
F2

ggsave(
  plot = last_plot(),
  filename = "Figures/Figure 4_Knowledge and Experience.png",
  height = 8,
  width = 8,
  units = "in",
  scale = .9,
  bg = "white"
)

rio::export(
knowledgeExperience %>%
  dplyr::select(Group, FacetTopic, Domain, Topic, N) %>%
  dplyr::arrange(Topic, Domain, FacetTopic, Group),
file = "Figures/Figure 4_Alt text counts.csv")

```
